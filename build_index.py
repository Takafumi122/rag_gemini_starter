import os
from pathlib import Path
# â˜… è¿½è¨˜: .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
from dotenv import load_dotenv
load_dotenv()

# RAGã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# --- è¨­å®šå€¤ ---
# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
DOC_DIR = Path("docs")
# ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
INDEX_DIR = Path("index")
# ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã¨ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ï¼ˆåˆ†å‰²ã—ãŸãƒ†ã‚­ã‚¹ãƒˆç‰‡ã®ã‚µã‚¤ã‚ºã¨é‡è¤‡å¹…ï¼‰
CHUNK_SIZE = 500
CHUNK_OVERLAP = 50
# ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«å
EMBEDDING_MODEL = "models/text-embedding-004"
# -----------------

def load_markdowns():
    """
    docs/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹ã€‚
    """
    print(f"--- 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {DOC_DIR} ---")
    
    # DirectoryLoader: æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ã¦ã® .md ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    loader = DirectoryLoader(
        str(DOC_DIR), 
        glob="**/*.md",
        show_progress=True,
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä¿æŒ
    )
    documents = loader.load()

    if not documents:
        print("ğŸš¨ ã‚¨ãƒ©ãƒ¼: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚docs/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã« .md ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return []

    print(f"ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(documents)}")

    print("--- 2. ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†å‰²ï¼ˆãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ï¼‰é–‹å§‹ ---")
    # RecursiveCharacterTextSplitter: è¤‡æ•°ã®åŒºåˆ‡ã‚Šæ–‡å­—ã‚’ä½¿ã£ã¦è³¢ãåˆ†å‰²
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        length_function=len,
        separators=["\n\n", "\n", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)
    print(f"ç”Ÿæˆã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunks)}")
    
    return chunks

def build():
    """
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆChromaDBï¼‰ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    """
    # ãƒãƒ£ãƒ³ã‚¯ã®å–å¾—
    chunks = load_markdowns()
    if not chunks:
        return

    print("--- 3. ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ– ---")
    try:
        # ç’°å¢ƒå¤‰æ•° GOOGLE_API_KEY ã¾ãŸã¯ GEMINI_API_KEY ã‚’ä½¿ç”¨
        embedding_model = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
    except Exception as e:
        print(f"ğŸš¨ ã‚¨ãƒ©ãƒ¼: Gemini Embeddingãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚{e}")
        return

    print(f"--- 4. ãƒ™ã‚¯ãƒˆãƒ«DBæ§‹ç¯‰ã¨ä¿å­˜: {INDEX_DIR} ---")
    
    # INDEX_DIRãŒãªã‘ã‚Œã°ä½œæˆ
    INDEX_DIR.mkdir(exist_ok=True)

    # ChromaDBã«ãƒãƒ£ãƒ³ã‚¯ã‚’æ ¼ç´ã—ã€ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ã¨ãƒ‡ã‚£ã‚¹ã‚¯ã¸ã®æ°¸ç¶šåŒ–ã‚’å®Ÿè¡Œ
    vector_db = Chroma.from_documents(
        documents=chunks,
        embedding=embedding_model,
        persist_directory=str(INDEX_DIR)
    )
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ°¸ç¶šåŒ–ã‚’æ˜ç¤ºçš„ã«å®Ÿè¡Œ
    vector_db.persist()
    print(f"âœ… Index saved at {INDEX_DIR} directory. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    # ç’°å¢ƒå¤‰æ•°GOOGlE_API_KEYã®ç¢ºèª
    if 'GOOGLE_API_KEY' not in os.environ and 'GEMINI_API_KEY' not in os.environ:
        print("ğŸš¨ ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° 'GOOGLE_API_KEY' ã¾ãŸã¯ 'GEMINI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    else:
        build()